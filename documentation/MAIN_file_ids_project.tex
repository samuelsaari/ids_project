
%%--------------------------------------------------

%READ ME 
% Use this like Google docs. Track changes should be on (for you). Make any changes you desire (or comment) and I will make sure it compiles nicely should you encounter any issues.

% This short video will help you get started if needed:
% https://youtu.be/S6Si-F5ArIw 
% The video is for an old article but the principle is the same

% Cite like this: (Smith 2021 "Article title") and I will look it up.

% Note that the preamble is in the 0dPreamble_..._Maki.sty file
% ---> Preamble includes settings, author information, affiliations, and title of the document.

%%%-----------------------------------------------


%%%-----------------------------------------------
% Some settings that cannot be included in the 0Preamble-file

\RequirePackage{snapshot} % creates a .dep file of the dependencies
\documentclass[a4paper,12pt,bibliography=totoc,numbers=noenddot,sfdefaults=false,abstract=true,notitlepage]{scrartcl} % NB!  % NB! TexPublish reguires this to be on a single line
\usepackage{0Preamble_ids}

% include all figures inserted with \InsertFloat in texcount
%TC:macroword \InsertFloat [float]

% do not count stuff inside begin{comment/B}..end{comment/B} 
%TC:group comment 0 0
%TC:group B 0 0

%%%%-----------------------------
\addbibresource{0MyLibrary.bib}

\begin{document} % Document starts here
	
	
	\begin{singlespace}
	\maketitle % Brings front page information from the 0Preamble-file
		
	% 	\begin{abstract}
	% 		{\parindent0pt % disables indentation for all the text between { and }
				
	% 			\blindtext
				
	% 			\keywords{xx $\cdot$ yyy  }
	% 		}% Indent end
	% 		consider summarising the main research questions /. hypotheses in the abstract -- at least 90% of people read only the abstract.
	% 	\end{abstract} \hspace{10pt}
		
	\end{singlespace}


	% \newpage
	
	%%%%-----------------------------------------------
	%%%% Introduction
	
	%\clearpage %OBS!!
	\section{Introduction}\label{intro}
	
	%%%% Define a research territory (1)
	%% General context of the work (1a)  
	%% Narrower research area and statement of its importance (1b)
	Play\textemdash coming together to engage in a common recreational activity\textemdash is a human universal \autocite{brownHumanUniversalsHuman2004} and essential part in human development \autocite{smithPlayTypesFunctions2005,pellegriniRolePlayHuman2009}. Board games are a popular and accessible form of play that bring family, friends and strangers alike together, and promote well-being across the life-span \autocite{dellangelaBoardGamesEmotional2020,solway2011wellness}.

	%%%% Establish a niche (2)
	%% Identification of a gap or other need for research (2a)
	% Specific research question meeting the identified need (2b)
	But what if a group of people have outplayed the games they own and would like to find some new ones? There are at least 150.000 different board games out there \autocite{wordsratedBoardGamesStatistics2025} so finding a good match can be a time consuming process. A service that would suggest new board games based on the individual taste could come in handy on such occasions.
	
	%%% Summary
	% Summary of approach to answer the research question 3a
	%Announcement of principal findings
	This technical report will outline the steps we made and lessons learned to create a recommendation system for new board games based on the user's ratings in BoardGameGeek.com (BGG) database as well as the technical details of setting up a webpage *LINK TO WEBSITE* through which users can find recommendations for new board games. To achieve this, we used non-negative matrix factorization (NMF) with a selected users' review scores to create tailored suggestions for new board games.
	
	
	%%%%-----------------------------------------------
	%%%% Data and Methods
	
	
	\section{Data}\label{data}

	%BGG Data
	We chose the biggest board game ratings database BoardGameGeek.com to fetch user ratings and board game metadata, such as playing mechanics and category. As it is openly available, it having a data access was simple and there were no data privacy issues to be addressed.

	Since there are 2.7 million users  and 150.000 boardgames in BGG \autocite{didymus-trueBoardGameGeeksSupportDrive2024,wordsratedBoardGamesStatistics2025}, fetching all of them would not be feasible with the API interface, at least within this project. Since many users have left no or few reviews, the data would be too sparse if we had taken a random sample. To get a compromise between training matrix sparsity, time constraints and selection bias, we decided to choose x guilds (online discussion groups) that represent different geographic regions, target audiences (teens, parents, seniors), genres as well as general and special interest groups. This way we could get X reviews from Y reviewers about Z games. The sampling strategy did bias our distribution towards active users, but also allows for reliable training. Users with only few reviews would make the estimation computationally intensive and possibly unreliable.
	
	We decided to load our data via the BGG XML API \autocite{bbgBGGXMLAPI22025}. While the data is well preprocessed and clean, getting the data was no simple task.

	First, the API has rate limits that we had to find out by trial and error. We used a base delay of .75 seconds and if the rate was limited, increased the delay exponentially and waited for the maximum of one minute. The maximum batch size for games was 20 and it took some time to find out why the game metadata coverage was so low on larger test runs.

	Second, since the game metadata fetching was unreliable even with the exponential backoff time, we used a game metadata cachefile to make sure that if a game metadata had been fetched successfully once, it was stored  on the project home directory.

	Finally, we included only users with at least 25 reviews and fetched the most popular games first to avoid training data matrix sparsity.
	
	
	\section{Methods}\label{methods}

	Using review scores is the single best way of generating recommendations \autocite{epsteinRangeWhyGeneralists2021}. It seems counterintutive as one would think that categories, genres, sales or other available metadata would be equally helpful. Based on this empirical finding and the scope of the project, we chose to focus solely on the review scores. Upon fetching the recommendations, we did, howerever, provide game metadata for the user to help in determining which of the recommendations to use. These included publication year, weight (difficulty), average rating (based on all reviews), number of all ratings, categories (genres), and mechanics (how the game is played). 

	The method we chose to use for data analysis was non-negative matrix factorization (NMF), which is an unsupervised learning algorithm \autocite{dalyStepbyStepNMFExample2023}. (miksi valittiin?). 
	
	We combined the usernames and game names into a matrix with the corresponding ratings from each user and imputed NaN's with SoftImpute. For the NMF model we also had to calculate the optimal rank, which we did by iteratively running multiple NMF models (Selitetään miten meidän defaulttiin päädyttiin.). With the calculated default optimal rank we then ran the NMF model with sklearn's implementation and the resulting recommendation matrix giving us estimates on how the user may rate games they haven't rated yet. We used these estimations to show the user the top games they haven't rated yet as well as the actual estimated rating they might give them.

	%@Ahti, voitko kirjoittaa tähän frontista?
	
	Regarding the UI we kept it very simple with a Boostrap table to show the details for each game and a Chart.js bar table to show the rating distribution within our dataset. Otherwise no other visualization methods were used in our project.
	
	
	%%%%-----------------------------------------------
	%%%% Results
	
	\section{Results}\label{results}
	
	
	% Linkki nettisivulle ja selostetaan toiminnallisuudesta jotain, jos joitain jäänyt kertomatta metodeissa. Tämä voi tarvittaessa olla lyhyt
	
	%kuinka hyvin nmf toimi, virhe
	%@Ahti
	
	
	
	
	%%%%-----------------------------------------------
	%%%% Discussion and conclusion
	
	\section{Discussion}\label{discussion}

	We created a board game recommendation webpage based on a sample of 200.000 board game reviews from 1000 active BoarGameGeek.com users to help BoardGameGeek users\textemdash or anyone\textemdash find new boardgames that match their taste. Below we will reflect on the lessons learned from our project.
	
	%%%% Interpretation of results to answer research question
	We found it interesting how simple it is to create a recommendation algorithm that works fairly well. It is reassuring that one can first build something that works and then make it more complex. That is essentially what we did, and will definitely use a similar routine for future data science projects.
	
	%% Surprising results?
	
	%%%% Possible weaknesses
	Setting up API was a valuable learning experience. If we were to redo this, it would probably be better to rely on a ready made data dump. This is because the rate limits were very restrictive and getting the data in tidy format involved quite a bit of work. If this project was expanded, we would use the whole BGG database as a training data to get even better estimates. For the scope of this mini-project, 200,000 reviews should be enough.

	%@Sanni, mitä sinä opit tai mitä pohdintoja nousi tätä tehdessä?
	
	% Pitää ehkä vähän restructure, mutta lisään nyt tähän kohtaan podintoja anyway. (Myös on vastaan toista pohdintaa myöhemmin)
	
	Generally the project ended up being less complex than we had wished, though we didn't exactly depart from our initial plan. The final state of the project quite close to the minimum viable product we were expecting to get. Mainly we weren't able to implement the ideas we for non-users being able to also get recommendations. Other ideas we had included more visualization as well as using the categories in some meaningful way. Ultimately this was mainly due to scheduling problems as well as partly due to setting such a clear division for work tasks. Perhaps if we had found time to work as a team rather than waiting on each person to finish their indivitual tasks, we could've progressed more steadily and had time for other additions.

	%@Ahti,mitä sinä opit tai mitä pohdintoja nousi tätä tehdessä?
	
	%%%% Broader implications / Comparison or synthesis with results from literature
	%% how does relate to other research questions?
	%% does it support current hypotheses in your field?
	%% how does it relate with literature (wider than topic of this paper)
	We also learned how using everyone's strengths can contributed into a great product. One of us had solid experience from front end and boardgames; another from creating appealing user interface and keeping repositories organized; yet another from statistics and managing projects more generally. Combining these abilities allowed us to have a clear division of labor among the group and make a steady progress with weekly checkpoints.
	
	
	%%%% Prospects for future research
	%, and have an option to rate a curated list to get recommendations even without a BGG user account.
	Other than using a larger training data, future work could try out different recommendation algorithms and optimize them with more rigor.
	
	% Conclusion for Article
	This project serves as a good example that when the problem definition is clear cut and the product creates true added value for the user, it is easy to manage a complex workflow like ours. With a clear purpose and goal in mind, it is easier to stay on track and strive for a product that will bring added value to users.
	
	%\clearpage
	%%%--------cd C:\Users\mmak\OneDrive - Väestöliitto ry\FLH-THESIS\1_determinants\1publish_determinantscd C:\Users\mmak\OneDrive - Väestöliitto ry\FLH-THESIS\1_determinants\1publish_determinants---------------------------------------
	% Bibliography
	\FloatBarrier
	%\begin{spacing}{1.3} 
	\printbibliography
	%\end{spacing}
	
	
	%TC:ignore 
	% check that texcount works as intended
	
	%%%-----------------------------------------------
	%% Figures for Submit (S) version
	
	% Figures and tables that appear in the body here again for the submit (S) version

	
	\savepage{lastpage} % page count 
	
	%-------------------------------------------------------------
	% Appendix
	%-------------------------------------------------------------
	% First some settings, bear with me!
	\clearpage
	\setcounter{secnumdepth}{3} % add numbers to section headings, needed for prefix in the figures
	\appendix % start appendix
	%\counterwithin{figure}{section} % A prefix for figures
	%\counterwithin{table}{section} % A prefix for tables
	%\stepcounter{section} % stars numbers from 1 onwards (A.1 etc)
	
	% Custom prefixes
	\renewcommand{\thefigure}{S\arabic{figure}}
	\setcounter{figure}{0}
	\renewcommand{\thetable}{S\arabic{table}}
	\setcounter{table}{0}
	
	\pagenumbering{arabic} % page count in arabic numbers
	\renewcommand{\thepage}{Appendix \Roman{page}} % A. prefix for  page numbering
	
	\addsec{Appendix}\label{------APPENDIX------} % KOMA-class section without numbers (same as \section*{}), but will keep the "A."-prefixes in floats and include the section in table of contents
	
	\FloatBarrier
	
	\clearpage
	
	
	
	
	%TC:endignore
	\savepage{applastpage} % page count
	
\end{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%---------------------
